{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OSORpPs3oSui","outputId":"2bcb83f8-2b69-4a46-988e-6db7e54a2c7f","executionInfo":{"status":"ok","timestamp":1753314921298,"user_tz":-330,"elapsed":23085,"user":{"displayName":"Bhavesh Srivastava","userId":"06799606870926618265"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["pip install streamlit pyngrok"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Hzch-cBd7jC","outputId":"e7e26f32-c49c-412b-bfa3-caedd233d776","collapsed":true,"executionInfo":{"status":"ok","timestamp":1753314931083,"user_tz":-330,"elapsed":9801,"user":{"displayName":"Bhavesh Srivastava","userId":"06799606870926618265"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting streamlit\n","  Downloading streamlit-1.47.0-py3-none-any.whl.metadata (9.0 kB)\n","Collecting pyngrok\n","  Downloading pyngrok-7.2.12-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n","Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n","Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n","Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n","Collecting watchdog<7,>=2.1.5 (from streamlit)\n","  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n","Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n","  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.25.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.48.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n","Downloading streamlit-1.47.0-py3-none-any.whl (9.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyngrok-7.2.12-py3-none-any.whl (26 kB)\n","Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n","Successfully installed pydeck-0.9.1 pyngrok-7.2.12 streamlit-1.47.0 watchdog-6.0.0\n"]}]},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.models import load_model\n","import joblib\n","import matplotlib.pyplot as plt\n","\n","# Load all models and encoders\n","@st.cache_resource\n","def load_all_models():\n","    # LSTM Autoencoder models\n","    lstm_model = load_model('/content/drive/MyDrive/anomaly_files/LSTM/lstm_autoencoder_anomaly_detection.h5')\n","    lstm_scaler = joblib.load('/content/drive/MyDrive/anomaly_files/LSTM/standard_scaler.save')\n","\n","    # CNN Fault Detection models\n","    cnn_model = load_model('/content/drive/MyDrive/anomaly_files/CNN/cnn_fault_detection.keras')\n","    cnn_encoder = joblib.load('/content/drive/MyDrive/anomaly_files/CNN/label_encoder_cnn.joblib')\n","\n","    # ANN Fault Detection models\n","    ann_model = load_model('/content/drive/MyDrive/anomaly_files/ANN/fault_detection_model.h5')\n","    ann_encoder = joblib.load('/content/drive/MyDrive/anomaly_files/ANN/label_encoder_aan.joblib')\n","\n","    return lstm_model, lstm_scaler, cnn_model, cnn_encoder, ann_model, ann_encoder\n","\n","# Load all models\n","lstm_model, lstm_scaler, cnn_model, cnn_encoder, ann_model, ann_encoder = load_all_models()\n","\n","# Signal segmentation function\n","def segment_signal(signal, win_len, stride=200):\n","    if len(signal) < win_len:\n","        return None\n","    return np.array([signal[i:i + win_len] for i in range(0, len(signal) - win_len + 1, stride)])\n","\n","# Function to create sequences for LSTM\n","def create_sequences(data, seq_length):\n","    sequences = []\n","    for i in range(len(data) - seq_length + 1):\n","        sequence = data[i:i+seq_length]\n","        sequences.append(sequence)\n","    return np.array(sequences)\n","\n","# Function to calculate reconstruction error\n","def calculate_reconstruction_error(model, data):\n","    predictions = model.predict(data)\n","    mse = np.mean(np.power(data - predictions, 2), axis=1)\n","    return mse\n","\n","# Streamlit app\n","def main():\n","    st.title(\"Anomaly Detection & Fault Classification System\")\n","    st.write(\"Upload a CSV file containing vibration data for analysis\")\n","\n","    # File upload\n","    uploaded_file = st.file_uploader(\"Choose a CSV file\", type=\"csv\")\n","\n","    if uploaded_file is not None:\n","        try:\n","            # Read the uploaded file\n","            df = pd.read_csv(uploaded_file)\n","            st.success(\"File successfully loaded!\")\n","\n","            # Automatically select first numeric column\n","            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n","\n","            if not numeric_cols:\n","                st.error(\"No numeric columns found in the CSV file\")\n","                return\n","\n","            selected_col = numeric_cols[0]\n","            st.write(f\"Analyzing\")\n","\n","            # ========== ANOMALY DETECTION SECTION ==========\n","            st.header(\"Step 1: Anomaly Detection\")\n","\n","            # Preprocess the data\n","            X = df[selected_col].values.reshape(-1, 1)\n","            X_scaled = lstm_scaler.transform(X)\n","\n","            # Create sequences\n","            SEQ_LENGTH = 30\n","            X_sequences = create_sequences(X_scaled, SEQ_LENGTH)\n","\n","            if len(X_sequences) == 0:\n","                st.error(f\"Not enough data points to create sequences. Need at least {SEQ_LENGTH} data points.\")\n","                return\n","\n","            # Calculate reconstruction error\n","            with st.spinner('Detecting anomalies...'):\n","                errors = calculate_reconstruction_error(lstm_model, X_sequences)\n","\n","            # Determine threshold\n","            threshold = np.percentile(errors, 85)\n","\n","\n","            # Detect anomalies\n","            anomalies = errors > threshold\n","\n","            # Display results\n","            st.subheader(\"Anomaly Detection Results\")\n","\n","            # Plot results\n","            fig, ax = plt.subplots(figsize=(10, 4))\n","            normal_indices = np.where(~anomalies)[0]\n","            anomaly_indices = np.where(anomalies)[0]\n","\n","            ax.plot(normal_indices, errors[normal_indices], 'bo', markersize=3, label='Normal')\n","            if len(anomaly_indices) > 0:\n","                ax.plot(anomaly_indices, errors[anomaly_indices], 'ro', markersize=5, label='Anomaly')\n","            ax.axhline(y=threshold, color='r', linestyle='-', label='Threshold')\n","            ax.set_title(f'Anomaly Detection Results')\n","            ax.set_ylabel('Reconstruction Error')\n","            ax.set_xlabel('Sample Index')\n","            ax.legend()\n","\n","            st.pyplot(fig)\n","\n","            # Summary statistics\n","            st.write(f\"Total samples analyzed: {len(X_sequences)}\")\n","            st.write(f\"Number of anomalies detected: {np.sum(anomalies)}\")\n","            st.write(f\"Anomaly threshold (85th percentile): {threshold:.4f}\")\n","\n","            # Show anomalies in a table\n","            if np.sum(anomalies) > 0:\n","                # Create a dataframe with the original data points marked as anomalies\n","                result_df = df.copy()\n","                result_df.columns=['Vibration']\n","                result_df['Anomaly'] = False\n","                result_df['Reconstruction_Error'] = np.nan\n","\n","                # Assign errors to the last point of each sequence\n","                for idx in range(len(errors)):\n","                    pos = idx + SEQ_LENGTH - 1\n","                    if pos < len(result_df):\n","                        result_df.loc[pos, 'Reconstruction_Error'] = errors[idx]\n","                        result_df.loc[pos, 'Anomaly'] = anomalies[idx]\n","\n","                anomaly_df = result_df[result_df['Anomaly'] == True]\n","                st.subheader(\"Detected Anomalies\")\n","                st.write(anomaly_df)\n","\n","                # ========== FAULT CLASSIFICATION SECTION ==========\n","                st.header(\"Step 2: Fault Classification\")\n","\n","                if st.button(\"Classify Detected Anomalies\"):\n","                    with st.spinner('Classifying anomalies...'):\n","                        # Prepare anomaly segments for classification\n","                        anomaly_segments = []\n","                        for idx in anomaly_indices:\n","                            start_idx = max(0, idx - 500)  # Get 500 points before anomaly\n","                            end_idx = min(len(X), idx + 500)  # Get 500 points after anomaly\n","                            segment = X[start_idx:end_idx]\n","                            anomaly_segments.append(segment)\n","\n","                        # CNN Classification\n","                        st.subheader(\"CNN Model Classification\")\n","                        cnn_predictions = []\n","                        for seg in anomaly_segments:\n","                            cnn_windows = segment_signal(seg, win_len=500)\n","                            if cnn_windows is not None and len(cnn_windows) > 0:\n","                                preds = cnn_model.predict([cnn_windows]*3)\n","                                pred_class = np.argmax(preds, axis=1)\n","                                faults = cnn_encoder.inverse_transform(pred_class)\n","                                cnn_predictions.extend(faults)\n","\n","                        if cnn_predictions:\n","                            fault_types, counts = np.unique(cnn_predictions, return_counts=True)\n","                            cnn_results = pd.DataFrame({\n","                                'Fault Type': fault_types,\n","                                'Count': counts,\n","                                'Percentage': [f'{c/len(cnn_predictions)*100:.1f}%' for c in counts]\n","                            })\n","                            st.table(cnn_results)\n","                        else:\n","                            st.warning(\"CNN couldn't process any anomaly segments\")\n","\n","                        # ANN Classification\n","                        st.subheader(\"ANN Model Classification\")\n","                        ann_predictions = []\n","                        for seg in anomaly_segments:\n","                            ann_windows = segment_signal(seg, win_len=1000)\n","                            if ann_windows is not None and len(ann_windows) > 0:\n","                                preds = ann_model.predict(ann_windows)\n","                                pred_class = np.argmax(preds, axis=1)\n","                                faults = ann_encoder.inverse_transform(pred_class)\n","                                ann_predictions.extend(faults)\n","\n","                        if ann_predictions:\n","                            fault_types, counts = np.unique(ann_predictions, return_counts=True)\n","                            ann_results = pd.DataFrame({\n","                                'Fault Type': fault_types,\n","                                'Count': counts,\n","                                'Percentage': [f'{c/len(ann_predictions)*100:.1f}%' for c in counts]\n","                            })\n","                            st.table(ann_results)\n","                        else:\n","                            st.warning(\"ANN couldn't process any anomaly segments\")\n","\n","                # Option to download anomalies\n","                csv = anomaly_df.to_csv(index=False)\n","                st.download_button(\n","                    label=\"Download Anomalies Report\",\n","                    data=csv,\n","                    file_name='detected_anomalies.csv',\n","                    mime='text/csv',\n","                )\n","            else:\n","                st.success(\"No anomalies detected in the data!\")\n","\n","        except Exception as e:\n","            st.error(f\"An error occurred: {str(e)}\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"jOb6OJ5csehv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cf544b17-1c1c-4c6c-9fc2-aea9ecf27318","executionInfo":{"status":"ok","timestamp":1753314931207,"user_tz":-330,"elapsed":118,"user":{"displayName":"Bhavesh Srivastava","userId":"06799606870926618265"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing app.py\n"]}]},{"cell_type":"code","source":["from pyngrok import ngrok\n","ngrok.set_auth_token(\"2ubujdtAi5h5JKYCfAm28KXigdg_67UvKVFpECE1opeu34gbP\")\n","def run_streamlit():\n","  os.system('streamlit run /content/app.py --server.port 8000')\n","import os\n","from threading import Thread\n","from pyngrok import ngrok\n","ngrok.kill()\n","ngrok.set_auth_token(\"2ubujdtAi5h5JKYCfAm28KXigdg_67UvKVFpECE1opeu34gbP\")\n","!ngrok config add-authtoken'2ubujdtAi5h5JKYCfAm28KXigdg_67UvKVFpECE1opeu34gbP'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ISFJKMe-xojs","outputId":"a1c53672-d99c-4ae8-a125-104f278f2143","executionInfo":{"status":"ok","timestamp":1753314931983,"user_tz":-330,"elapsed":765,"user":{"displayName":"Bhavesh Srivastava","userId":"06799606870926618265"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["NAME:\n","  config - update or migrate ngrok's configuration file\n","\n","USAGE:\n","  ngrok config [flags]\n","\n","DESCRIPTION: \n","  The config command gives a quick way to create or update ngrok's configuration\n","  file. Use 'add-authtoken' or 'add-api-key' to set the corresponding properties.\n","\n","  Use 'check' to test a configuration file for validity. If you have an old\n","  configuration file, you can also use 'upgrade' to automatically migrate to the\n","  latest version.\n","\n","COMMANDS:\n","  add-api-key                    save api key to configuration file\n","  add-authtoken                  save authtoken to configuration file\n","  add-connect-url                adds the connect URL (connect_url) to configuration file for custom agent ingress\n","  add-server-addr                alias of add-connect-url\n","  check                          check configuration file\n","  edit                           edit configuration file\n","  upgrade                        auto-upgrade configuration file\n","\n","OPTIONS:\n","      --config strings   path to config files; they are merged if multiple\n","  -h, --help             help for config\n"]}]},{"cell_type":"code","source":["thread=Thread(target=run_streamlit)\n","thread.start()\n","\n","public_url = ngrok.connect(addr='8000' ,proto='http',bind_tls=True)\n","print(public_url)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QzEmgFvrxrSe","outputId":"d1704f77-27ec-485a-ad3f-53f8e31c72dc","executionInfo":{"status":"ok","timestamp":1753314932286,"user_tz":-330,"elapsed":292,"user":{"displayName":"Bhavesh Srivastava","userId":"06799606870926618265"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["NgrokTunnel: \"https://7d4c186e7dbe.ngrok-free.app\" -> \"http://localhost:8000\"\n"]}]},{"cell_type":"markdown","source":["# Other way to Run streamlit"],"metadata":{"id":"vpTkWD-_wnBq"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nLYMjB9qEETu","outputId":"0815337a-6c82-4104-a604-2c1fda0c601f"},"outputs":[{"output_type":"stream","name":"stdout","text":["34.45.60.143\n"]}],"source":["!wget -q -O - ipv4.icanhazip.com"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h7dOMezYIWii","outputId":"a50cff66-3ec2-497e-ed4b-09f22a20c90e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://clear-houses-fail.loca.lt\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:pyngrok.process.ngrok:t=2025-05-04T12:42:45+0000 lvl=warn msg=\"failed to open private leg\" id=b1cf9ba40a24 privaddr=localhost:8001 err=\"dial tcp 127.0.0.1:8001: connect: connection refused\"\n","WARNING:pyngrok.process.ngrok:t=2025-05-04T12:42:46+0000 lvl=warn msg=\"failed to open private leg\" id=cb5062ccaf9a privaddr=localhost:8001 err=\"dial tcp 127.0.0.1:8001: connect: connection refused\"\n","WARNING:pyngrok.process.ngrok:t=2025-05-04T12:42:47+0000 lvl=warn msg=\"failed to open private leg\" id=d4e4cd710eeb privaddr=localhost:8001 err=\"dial tcp 127.0.0.1:8001: connect: connection refused\"\n","WARNING:pyngrok.process.ngrok:t=2025-05-04T12:42:48+0000 lvl=warn msg=\"failed to open private leg\" id=b5337016f61f privaddr=localhost:8001 err=\"dial tcp 127.0.0.1:8001: connect: connection refused\"\n","WARNING:pyngrok.process.ngrok:t=2025-05-04T12:42:49+0000 lvl=warn msg=\"failed to open private leg\" id=0bdc10957f72 privaddr=localhost:8001 err=\"dial tcp 127.0.0.1:8001: connect: connection refused\"\n","WARNING:pyngrok.process.ngrok:t=2025-05-04T12:42:50+0000 lvl=warn msg=\"failed to open private leg\" id=1364246912f8 privaddr=localhost:8001 err=\"dial tcp 127.0.0.1:8001: connect: connection refused\"\n","WARNING:pyngrok.process.ngrok:t=2025-05-04T12:43:50+0000 lvl=warn msg=\"failed to open private leg\" id=bca4b0a2ef55 privaddr=localhost:8001 err=\"dial tcp 127.0.0.1:8001: connect: connection refused\"\n","WARNING:pyngrok.process.ngrok:t=2025-05-04T12:43:51+0000 lvl=warn msg=\"failed to open private leg\" id=f49a6dc1b67d privaddr=localhost:8001 err=\"dial tcp 127.0.0.1:8001: connect: connection refused\"\n","WARNING:pyngrok.process.ngrok:t=2025-05-04T12:43:52+0000 lvl=warn msg=\"failed to open private leg\" id=70f287abfa41 privaddr=localhost:8001 err=\"dial tcp 127.0.0.1:8001: connect: connection refused\"\n","WARNING:pyngrok.process.ngrok:t=2025-05-04T12:43:53+0000 lvl=warn msg=\"failed to open private leg\" id=11f35ca82b91 privaddr=localhost:8001 err=\"dial tcp 127.0.0.1:8001: connect: connection refused\"\n","WARNING:pyngrok.process.ngrok:t=2025-05-04T12:43:54+0000 lvl=warn msg=\"failed to open private leg\" id=7adcc79b1887 privaddr=localhost:8001 err=\"dial tcp 127.0.0.1:8001: connect: connection refused\"\n","WARNING:pyngrok.process.ngrok:t=2025-05-04T12:43:56+0000 lvl=warn msg=\"failed to open private leg\" id=e5487ffc8f94 privaddr=localhost:8001 err=\"dial tcp 127.0.0.1:8001: connect: connection refused\"\n","WARNING:pyngrok.process.ngrok:t=2025-05-04T12:44:13+0000 lvl=warn msg=\"failed to open private leg\" id=edcd0df405b9 privaddr=localhost:8001 err=\"dial tcp 127.0.0.1:8001: connect: connection refused\"\n","WARNING:pyngrok.process.ngrok:t=2025-05-04T12:44:14+0000 lvl=warn msg=\"failed to open private leg\" id=e0f9be637ea1 privaddr=localhost:8001 err=\"dial tcp 127.0.0.1:8001: connect: connection refused\"\n"]},{"output_type":"stream","name":"stdout","text":["^C\n"]}],"source":["!streamlit run /content/app.py &>/dev/null&\n","!npx localtunnel --port 8501"]},{"cell_type":"code","source":["!gdown 1-4-RUk-8BQM7gWTtHgWJ2o0wMgxK7bP2\n","!gdown 1-5Ig_ZbLowa90_ZlWr14euATiKj3n2dv\n","!gdown 1-00l3kVmsKa1AV-zAJ74ZIQ7BeUKmX5G\n","!gdown 14245PPnFiVgyNyDpU9r5hHoeJziIp46m\n","!gdown 1WSg9XTIAHIonGgj8_-UKaxGaqSzj4E-V\n","!gdown 1nvalePgdwsKwBs8IAkhZ6OzRTSj9cKvE"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"ToVCC_fPWIbW","outputId":"356c3fbe-655d-4ea1-c6bc-364ac93675ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1-4-RUk-8BQM7gWTtHgWJ2o0wMgxK7bP2\n","To: /content/label_encoder_cnn.joblib\n","100% 663/663 [00:00<00:00, 2.89MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1-5Ig_ZbLowa90_ZlWr14euATiKj3n2dv\n","To: /content/cnn_fault_detection.keras\n","100% 11.5M/11.5M [00:00<00:00, 138MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1-00l3kVmsKa1AV-zAJ74ZIQ7BeUKmX5G\n","To: /content/label_encoder_aan.joblib\n","100% 663/663 [00:00<00:00, 2.78MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=14245PPnFiVgyNyDpU9r5hHoeJziIp46m\n","To: /content/fault_detection_model.h5\n","100% 20.6M/20.6M [00:00<00:00, 59.8MB/s]\n"]}]}]}